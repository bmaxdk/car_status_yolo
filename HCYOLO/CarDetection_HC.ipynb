{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42b9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020346aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e7274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "print(classes)#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e90ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "[381, 1547, 48, 87]\n",
      "true\n",
      "[1927, 1236, 67, 146]\n",
      "true\n",
      "[102, 1541, 60, 80]\n",
      "Image is successfully saved as file.\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image.jpg')\n",
    "height, width, _ = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "#                                 normalize, decide image 416x415, we are not going to any mean subtraction, bgr image to rgb order, not going to do crop)\n",
    "# for b in blob:\n",
    "#     for n, img_blob in enumerate(b):\n",
    "#         cv2.imshow(str(n), img_blob)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "output_laters_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_laters_names)\n",
    "\n",
    "boxes = [] # extract the coundary boxes\n",
    "confidences = [] # store confidences\n",
    "class_ids = [] # class id which present predicted class\n",
    "\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:] #used to store all the classes prediction\n",
    "        # we want to identify scores\n",
    "        class_id = np.argmax(scores) #find the location contains highes scores location\n",
    "        confidence = scores[class_id] # assign into confidence variable. because we want to make sure high confidence\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width) #x *width\n",
    "            center_y = int(detection[1]*height) #y *height\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            # to get position of upper left corner\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "    \n",
    "# print(len(boxes)) # how many object are being detected\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                                        #threshhold 50%, maximum surpression\n",
    "# print(indexes.flatten()) # how many boxes are redundence. in here around 12 redundence\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "traffic_light = []\n",
    "for i in indexes.flatten(): # loop to identify object detected\n",
    "    x, y, w, h = boxes[i] # extrac information back to boxes\n",
    "    label = str(classes[class_ids[i]]) # extrack back to 'str' cuz here only show number\n",
    "    confidence = str(round(confidences[i],2)) # extract confidences to str that show in pics\n",
    "    color = colors[i] # randomly pick colors to show each of object\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "    ###########################################\n",
    "    if label == 'traffic light':\n",
    "        print('true')\n",
    "        print([x,y,w,h])\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        traffic_light.append(cropped_image)\n",
    "    cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "\n",
    "for n, traffic_img in enumerate(traffic_light):\n",
    "#     cv2.imshow(str(n), traffic_img)\n",
    "    \n",
    "    # Convert the imageFrame in \n",
    "    # BGR(RGB color space) to \n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(traffic_img, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "    # Set range for red color and \n",
    "    # define mask\n",
    "    red_lower = np.array([136, 87, 111], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "  \n",
    "    # Set range for green color and \n",
    "    # define mask\n",
    "    green_lower = np.array([25, 52, 72], np.uint8)\n",
    "    green_upper = np.array([102, 255, 255], np.uint8)\n",
    "    green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "  \n",
    "    # Set range for blue color and\n",
    "    # define mask\n",
    "    blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "    blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "      \n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernal = np.ones((5, 5), \"uint8\")\n",
    "      \n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernal)\n",
    "    res_red = cv2.bitwise_and(traffic_img, traffic_img, \n",
    "                              mask = red_mask)\n",
    "      \n",
    "    # For green color\n",
    "    green_mask = cv2.dilate(green_mask, kernal)\n",
    "    res_green = cv2.bitwise_and(traffic_img, traffic_img,\n",
    "                                mask = green_mask)\n",
    "      \n",
    "#     # For blue color\n",
    "#     blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "#     res_blue = cv2.bitwise_and(imageFrame, imageFrame,\n",
    "#                                mask = blue_mask)\n",
    "   \n",
    "    # Creating contour to track red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            traffic_img = cv2.rectangle(traffic_img, (x, y), \n",
    "                                       (x + w, y + h), \n",
    "                                       (0, 0, 255), 2)\n",
    "              \n",
    "            cv2.putText(traffic_img, \"Red Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                        (0, 0, 255))    \n",
    "  \n",
    "    # Creating contour to track green color\n",
    "    contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            traffic_img = cv2.rectangle(traffic_img, (x, y), \n",
    "                                       (x + w, y + h),\n",
    "                                       (0, 255, 0), 2)\n",
    "              \n",
    "            cv2.putText(traffic_img, \"Green Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (0, 255, 0))\n",
    "    cv2.imshow(str(n), traffic_img)\n",
    "  \n",
    "  # Creating contour to track blue color\n",
    "#     contours, hierarchy = cv2.findContours(blue_mask,\n",
    "#                                            cv2.RETR_TREE,\n",
    "#                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     for pic, contour in enumerate(contours):\n",
    "#         area = cv2.contourArea(contour)\n",
    "#         if(area > 300):\n",
    "#             x, y, w, h = cv2.boundingRect(contour)\n",
    "#             imageFrame = cv2.rectangle(imageFrame, (x, y),\n",
    "#                                        (x + w, y + h),\n",
    "#                                        (255, 0, 0), 2)\n",
    "              \n",
    "#             cv2.putText(imageFrame, \"Blue Colour\", (x, y),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                         1.0, (255, 0, 0))\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#save matrix/array as image file\n",
    "isWritten = cv2.imwrite('image-2.jpg', img)\n",
    "\n",
    "if isWritten:\n",
    "    print('Image is successfully saved as file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87c522e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cropped_image \u001b[38;5;241m=\u001b[39m img[\u001b[43mY\u001b[49m:Y\u001b[38;5;241m+\u001b[39mH, X:X\u001b[38;5;241m+\u001b[39mW]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m([X,Y,W,H])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cropped_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "cropped_image = img[Y:Y+H, X:X+W]\n",
    "print([X,Y,W,H])\n",
    "plt.imshow(cropped_image)\n",
    "cv2.imwrite('contour1.png', cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109cda9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "803c706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "[381, 1547, 48, 87]\n",
      "true\n",
      "[1927, 1236, 67, 146]\n",
      "true\n",
      "[102, 1541, 60, 80]\n",
      "Image is successfully saved as file.\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image.jpg')\n",
    "height, width, _ = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "#                                 normalize, decide image 416x415, we are not going to any mean subtraction, bgr image to rgb order, not going to do crop)\n",
    "# for b in blob:\n",
    "#     for n, img_blob in enumerate(b):\n",
    "#         cv2.imshow(str(n), img_blob)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "output_laters_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_laters_names)\n",
    "\n",
    "boxes = [] # extract the coundary boxes\n",
    "confidences = [] # store confidences\n",
    "class_ids = [] # class id which present predicted class\n",
    "\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:] #used to store all the classes prediction\n",
    "        # we want to identify scores\n",
    "        class_id = np.argmax(scores) #find the location contains highes scores location\n",
    "        confidence = scores[class_id] # assign into confidence variable. because we want to make sure high confidence\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width) #x *width\n",
    "            center_y = int(detection[1]*height) #y *height\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            # to get position of upper left corner\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "    \n",
    "# print(len(boxes)) # how many object are being detected\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                                        #threshhold 50%, maximum surpression\n",
    "# print(indexes.flatten()) # how many boxes are redundence. in here around 12 redundence\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "traffic_light = []\n",
    "for i in indexes.flatten(): # loop to identify object detected\n",
    "    x, y, w, h = boxes[i] # extrac information back to boxes\n",
    "    label = str(classes[class_ids[i]]) # extrack back to 'str' cuz here only show number\n",
    "    confidence = str(round(confidences[i],2)) # extract confidences to str that show in pics\n",
    "    color = colors[i] # randomly pick colors to show each of object\n",
    "#     cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "    ###########################################\n",
    "    if label == 'traffic light':\n",
    "        print('true')\n",
    "        print([x,y,w,h])\n",
    "        traffic_img = img[y:y+h, x:x+w]\n",
    "#         cropped_image = img[y:y+h, x:x+w]\n",
    "\n",
    "#         # collect traffic_light\n",
    "#         traffic_light.append(cropped_image)\n",
    "        # Convert the image in BGR to HSV(hue-saturation-value) color space\n",
    "        hsvFrame = cv2.cvtColor(traffic_img, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "        # Set range for red color and \n",
    "        # define mask\n",
    "        red_lower = np.array([136, 87, 111], np.uint8)\n",
    "        red_upper = np.array([180, 255, 255], np.uint8)\n",
    "        red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "        # Set range for green color and \n",
    "        # define mask\n",
    "        green_lower = np.array([25, 62, 82], np.uint8)\n",
    "        green_upper = np.array([102, 255, 255], np.uint8)\n",
    "        green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "#         # Set range for blue color and\n",
    "#         # define mask\n",
    "#         blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "#         blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "#         blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "        # Morphological Transform, Dilation\n",
    "        # for each color and bitwise_and operator\n",
    "        # between imageFrame and mask determines\n",
    "        # to detect only that particular color\n",
    "        kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "        # For red color\n",
    "        red_mask = cv2.dilate(red_mask, kernal)\n",
    "        res_red = cv2.bitwise_and(traffic_img, traffic_img, \n",
    "                                  mask = red_mask)\n",
    "\n",
    "        # For green color\n",
    "        green_mask = cv2.dilate(green_mask, kernal)\n",
    "        res_green = cv2.bitwise_and(traffic_img, traffic_img,\n",
    "                                    mask = green_mask)\n",
    "\n",
    "    #     # For blue color\n",
    "    #     blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "    #     res_blue = cv2.bitwise_and(imageFrame, imageFrame,\n",
    "    #                                mask = blue_mask)\n",
    "\n",
    "        # Creating contour to track red color\n",
    "        contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         print('a1')\n",
    "#         print(hierarchy)\n",
    "        rg_eixit = False\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 300):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht), \n",
    "                                           (0, 0, 255), 2)\n",
    "\n",
    "#                 cv2.putText(traffic_img, \"Red Colour\", (xt, yt),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "#                             (0, 0, 255))    \n",
    "                cv2.putText(img, \"RED:\"+label+confidence, (x, y), font, 2, (0, 0, 255), 2) #put into text\n",
    "                rg_eixit = True\n",
    "#                 break\n",
    "\n",
    "        # Creating contour to track green color\n",
    "        contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         print('a2')\n",
    "#         print(hierarchy)\n",
    "\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 300):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht),\n",
    "                                           (0, 255, 0), 2)\n",
    "\n",
    "#                 cv2.putText(traffic_img, \"Green Colour\", (x, y),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, \n",
    "#                             1.0, (0, 255, 0))\n",
    "                cv2.putText(img, \"GREEN:\"+label + confidence, (x, y), font, 2, (0, 255, 0), 2) #put into text\n",
    "                rg_eixit = True\n",
    "    #                 break\n",
    "#         cv2.imshow(str(n), traffic_img)\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "#     else:\n",
    "        if not rg_eixit:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "\n",
    "    else:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "        cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "\n",
    "# for n, traffic_img in enumerate(traffic_light):\n",
    "# #     cv2.imshow(str(n), traffic_img)\n",
    "    \n",
    "#     # Convert the imageFrame in \n",
    "#     # BGR(RGB color space) to \n",
    "#     # HSV(hue-saturation-value)\n",
    "#     # color space\n",
    "#     hsvFrame = cv2.cvtColor(traffic_img, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "#     # Set range for red color and \n",
    "#     # define mask\n",
    "#     red_lower = np.array([136, 87, 111], np.uint8)\n",
    "#     red_upper = np.array([180, 255, 255], np.uint8)\n",
    "#     red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "  \n",
    "#     # Set range for green color and \n",
    "#     # define mask\n",
    "#     green_lower = np.array([25, 52, 72], np.uint8)\n",
    "#     green_upper = np.array([102, 255, 255], np.uint8)\n",
    "#     green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "  \n",
    "#     # Set range for blue color and\n",
    "#     # define mask\n",
    "#     blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "#     blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "#     blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "      \n",
    "#     # Morphological Transform, Dilation\n",
    "#     # for each color and bitwise_and operator\n",
    "#     # between imageFrame and mask determines\n",
    "#     # to detect only that particular color\n",
    "#     kernal = np.ones((5, 5), \"uint8\")\n",
    "      \n",
    "#     # For red color\n",
    "#     red_mask = cv2.dilate(red_mask, kernal)\n",
    "#     res_red = cv2.bitwise_and(traffic_img, traffic_img, \n",
    "#                               mask = red_mask)\n",
    "      \n",
    "#     # For green color\n",
    "#     green_mask = cv2.dilate(green_mask, kernal)\n",
    "#     res_green = cv2.bitwise_and(traffic_img, traffic_img,\n",
    "#                                 mask = green_mask)\n",
    "      \n",
    "# #     # For blue color\n",
    "# #     blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "# #     res_blue = cv2.bitwise_and(imageFrame, imageFrame,\n",
    "# #                                mask = blue_mask)\n",
    "   \n",
    "#     # Creating contour to track red color\n",
    "#     contours, hierarchy = cv2.findContours(red_mask,\n",
    "#                                            cv2.RETR_TREE,\n",
    "#                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "#     for pic, contour in enumerate(contours):\n",
    "#         area = cv2.contourArea(contour)\n",
    "#         if(area > 300):\n",
    "#             x, y, w, h = cv2.boundingRect(contour)\n",
    "#             traffic_img = cv2.rectangle(traffic_img, (x, y), \n",
    "#                                        (x + w, y + h), \n",
    "#                                        (0, 0, 255), 2)\n",
    "              \n",
    "#             cv2.putText(traffic_img, \"Red Colour\", (x, y),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "#                         (0, 0, 255))    \n",
    "  \n",
    "#     # Creating contour to track green color\n",
    "#     contours, hierarchy = cv2.findContours(green_mask,\n",
    "#                                            cv2.RETR_TREE,\n",
    "#                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "#     for pic, contour in enumerate(contours):\n",
    "#         area = cv2.contourArea(contour)\n",
    "#         if(area > 300):\n",
    "#             x, y, w, h = cv2.boundingRect(contour)\n",
    "#             traffic_img = cv2.rectangle(traffic_img, (x, y), \n",
    "#                                        (x + w, y + h),\n",
    "#                                        (0, 255, 0), 2)\n",
    "              \n",
    "#             cv2.putText(traffic_img, \"Green Colour\", (x, y),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, \n",
    "#                         1.0, (0, 255, 0))\n",
    "#     cv2.imshow(str(n), traffic_img)\n",
    "  \n",
    "#   # Creating contour to track blue color\n",
    "# #     contours, hierarchy = cv2.findContours(blue_mask,\n",
    "# #                                            cv2.RETR_TREE,\n",
    "# #                                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "# #     for pic, contour in enumerate(contours):\n",
    "# #         area = cv2.contourArea(contour)\n",
    "# #         if(area > 300):\n",
    "# #             x, y, w, h = cv2.boundingRect(contour)\n",
    "# #             imageFrame = cv2.rectangle(imageFrame, (x, y),\n",
    "# #                                        (x + w, y + h),\n",
    "# #                                        (255, 0, 0), 2)\n",
    "              \n",
    "# #             cv2.putText(imageFrame, \"Blue Colour\", (x, y),\n",
    "# #                         cv2.FONT_HERSHEY_SIMPLEX,\n",
    "# #                         1.0, (255, 0, 0))\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#save matrix/array as image file\n",
    "isWritten = cv2.imwrite('image-2.jpg', img)\n",
    "\n",
    "if isWritten:\n",
    "    print('Image is successfully saved as file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1586040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "515366b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "0.36545720331926407\n",
      "[238, 281, 742, 377]\n",
      "true\n",
      "[761, 134, 63, 114]\n",
      "true\n",
      "[44, 125, 73, 116]\n",
      "car\n",
      "0.0\n",
      "[888, 393, 48, 50]\n",
      "RED\n",
      "stop\n",
      "Image is successfully saved as file.\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread('image6.jpeg')\n",
    "img = cv2.imread('image3.jpg')\n",
    "\n",
    "height, width, _ = img.shape\n",
    "center_y, center_x = height/2, width/2\n",
    "height_range, width_range = height/7, width/7\n",
    "box1 = [center_x-width_range, center_y-height_range, center_x+width_range, center_y+height_range]\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "#                                 normalize, decide image 416x416, we are not going to any mean subtraction, bgr image to rgb order, not going to do crop)\n",
    "# for b in blob:\n",
    "#     for n, img_blob in enumerate(b):\n",
    "#         cv2.imshow(str(n), img_blob)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "output_laters_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_laters_names)\n",
    "\n",
    "boxes = [] # extract the coundary boxes\n",
    "confidences = [] # store confidences\n",
    "class_ids = [] # class id which present predicted class\n",
    "current_sig = None #RED, GREEN, None\n",
    "car_speed = \"increase\" #increase, decrease, stop\n",
    "car_iou_max = 0\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:] #used to store all the classes prediction\n",
    "        # we want to identify scores\n",
    "        class_id = np.argmax(scores) #find the location contains highes scores location\n",
    "        confidence = scores[class_id] # assign into confidence variable. because we want to make sure high confidence\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width) #x *width\n",
    "            center_y = int(detection[1]*height) #y *height\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            # to get position of upper left corner\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "    \n",
    "# print(len(boxes)) # how many object are being detected\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                                        #threshhold 50%, maximum surpression\n",
    "# print(indexes.flatten()) # how many boxes are redundence. in here around 12 redundence\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "traffic_light = []\n",
    "for i in indexes.flatten(): # loop to identify object detected\n",
    "    x, y, w, h = boxes[i] # extrac information back to boxes\n",
    "    label = str(classes[class_ids[i]]) # extrack back to 'str' cuz here only show number\n",
    "    confidence = str(round(confidences[i],2)) # extract confidences to str that show in pics\n",
    "    color = colors[i] # randomly pick colors to show each of object\n",
    "#     cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "    ###########################################\n",
    "    if label == 'traffic light':\n",
    "        print('true')\n",
    "        print([x,y,w,h])\n",
    "        traffic_img = img[y:y+h, x:x+w]\n",
    "#         cropped_image = img[y:y+h, x:x+w]\n",
    "\n",
    "#         # collect traffic_light\n",
    "#         traffic_light.append(cropped_image)\n",
    "        # Convert the image in BGR to HSV(hue-saturation-value) color space\n",
    "        hsvFrame = cv2.cvtColor(traffic_img, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "        # Set range for red color and \n",
    "        # define mask\n",
    "        red_lower = np.array([136, 87, 91], np.uint8)\n",
    "        red_upper = np.array([180, 255, 255], np.uint8)\n",
    "        red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "        # Set range for green color and \n",
    "        # define mask\n",
    "        green_lower = np.array([55, 102, 122], np.uint8)\n",
    "        green_upper = np.array([102, 255, 255], np.uint8)\n",
    "        green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "\n",
    "\n",
    "        # Morphological Transform, Dilation\n",
    "        # for each color and bitwise_and operator\n",
    "        # between imageFrame and mask determines\n",
    "        # to detect only that particular color\n",
    "        kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "        # For red color\n",
    "        red_mask = cv2.dilate(red_mask, kernal)\n",
    "        res_red = cv2.bitwise_and(traffic_img, traffic_img, \n",
    "                                  mask = red_mask)\n",
    "\n",
    "        # For green color\n",
    "        green_mask = cv2.dilate(green_mask, kernal)\n",
    "        res_green = cv2.bitwise_and(traffic_img, traffic_img,\n",
    "                                    mask = green_mask)\n",
    "\n",
    "\n",
    "        # Creating contour to track red color\n",
    "        contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "        rg_eixit = False\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 190):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht), \n",
    "                                           (0, 0, 255), 2)\n",
    "\n",
    "#                 cv2.putText(traffic_img, \"Red Colour\", (xt, yt),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "#                             (0, 0, 255))    \n",
    "                cv2.putText(img, \"RED:\"+label+confidence, (x, y), font, 2, (0, 0, 255), 2) #put into text\n",
    "                rg_eixit = True\n",
    "                current_sig = \"RED\"\n",
    "#                 break\n",
    "\n",
    "        # Creating contour to track green color\n",
    "        contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 300):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht),\n",
    "                                           (0, 255, 0), 2)\n",
    "\n",
    "#                 cv2.putText(traffic_img, \"Green Colour\", (x, y),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, \n",
    "#                             1.0, (0, 255, 0))\n",
    "                cv2.putText(img, \"GREEN:\"+label + confidence, (x, y), font, 2, (0, 255, 0), 2) #put into text\n",
    "                rg_eixit = True\n",
    "                current_sig = \"GREEN\"\n",
    "    #                 break\n",
    "#         cv2.imshow(str(n), traffic_img)\n",
    "\n",
    "\n",
    "\n",
    "#     else:\n",
    "        if not rg_eixit:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "\n",
    "    else:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "        cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "        \n",
    "    # #############################################################\n",
    "    if label == 'car':\n",
    "        print('car')\n",
    "        iou = intersection_over_union(box1, [x,y,w,h])\n",
    "#         iou = intersection_over_union([x,y,w,h],box1)\n",
    "        car_iou_max = max(iou, car_iou_max)\n",
    "        print(iou)\n",
    "#         print('car true')\n",
    "        print([x,y,w,h])\n",
    "        if car_iou_max > 0.2:\n",
    "            car_speed = 'stop'\n",
    "        elif 0.2 >= car_iou_max >0.01:\n",
    "            car_speed = 'decrease'\n",
    "        else:\n",
    "            car_speed = 'increase'\n",
    "#         print(w*h)\n",
    "#         print(height*width)\n",
    "#         print('car percentage: ')\n",
    "#         print((w*h)/(height*width))\n",
    "#         if (w*h)/(height*width) > 0.40:\n",
    "#             car_speed = 'stop'\n",
    "#         elif 0.40 >= (w*h)/(height*width) > 0.30:\n",
    "#             car_speed = 'decrease'\n",
    "#         else:\n",
    "#             car_speed = 'increase'\n",
    "            \n",
    "#         car_img = img[y:y+h, x:x+w]\n",
    "\n",
    "print(current_sig)\n",
    "print(car_speed)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#save matrix/array as image file\n",
    "isWritten = cv2.imwrite('image-3.jpg', img)\n",
    "\n",
    "if isWritten:\n",
    "    print('Image is successfully saved as file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b1f8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5493d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "decrease\n",
      "None\n",
      "Image is successfully saved as file.\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread('image.jpg')\n",
    "img = cv2.imread('shoes4.jpg')\n",
    "\n",
    "height, width, _ = img.shape\n",
    "center_y, center_x = height/2, width/2\n",
    "height_range, width_range = height/7, width/7\n",
    "box1 = [center_x-width_range, center_y-height_range, center_x+width_range, center_y+height_range]\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "#                                 normalize, decide image 416x416, we are not going to any mean subtraction, bgr image to rgb order, not going to do crop)\n",
    "# for b in blob:\n",
    "#     for n, img_blob in enumerate(b):\n",
    "#         cv2.imshow(str(n), img_blob)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "output_laters_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_laters_names)\n",
    "\n",
    "boxes = [] # extract the coundary boxes\n",
    "confidences = [] # store confidences\n",
    "class_ids = [] # class id which present predicted class\n",
    "current_sig = None #RED, GREEN, None\n",
    "car_speed = \"increase\" #increase, decrease, stop\n",
    "car_iou_max = 0\n",
    "stop_sign = 'None'\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:] #used to store all the classes prediction\n",
    "        # we want to identify scores\n",
    "        class_id = np.argmax(scores) #find the location contains highes scores location\n",
    "        confidence = scores[class_id] # assign into confidence variable. because we want to make sure high confidence\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width) #x *width\n",
    "            center_y = int(detection[1]*height) #y *height\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            # to get position of upper left corner\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "    \n",
    "# print(len(boxes)) # how many object are being detected\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                                        #threshhold 50%, maximum surpression\n",
    "# print(indexes.flatten()) # how many boxes are redundence. in here around 12 redundence\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "traffic_light = []\n",
    "for i in indexes.flatten(): # loop to identify object detected\n",
    "    x, y, w, h = boxes[i] # extrac information back to boxes\n",
    "    label = str(classes[class_ids[i]]) # extrack back to 'str' cuz here only show number\n",
    "    confidence = str(round(confidences[i],2)) # extract confidences to str that show in pics\n",
    "    color = colors[i] # randomly pick colors to show each of object\n",
    "#     cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "    condition = ''\n",
    "    ###########################################\n",
    "    if label == 'traffic light':\n",
    "#         print('true')\n",
    "#         print([x,y,w,h])\n",
    "        traffic_img = img[y:y+h, x:x+w]\n",
    "#         cropped_image = img[y:y+h, x:x+w]\n",
    "\n",
    "#         # collect traffic_light\n",
    "#         traffic_light.append(cropped_image)\n",
    "        # Convert the image in BGR to HSV(hue-saturation-value) color space\n",
    "        hsvFrame = cv2.cvtColor(traffic_img, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "        # Set range for red color and \n",
    "        # define mask\n",
    "        red_lower = np.array([136, 87, 91], np.uint8)\n",
    "        red_upper = np.array([180, 255, 255], np.uint8)\n",
    "        red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "        # Set range for green color and \n",
    "        # define mask\n",
    "        green_lower = np.array([55, 102, 122], np.uint8)\n",
    "        green_upper = np.array([102, 255, 255], np.uint8)\n",
    "        green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "\n",
    "\n",
    "        # Morphological Transform, Dilation\n",
    "        # for each color and bitwise_and operator\n",
    "        # between imageFrame and mask determines\n",
    "        # to detect only that particular color\n",
    "        kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "        # For red color\n",
    "        red_mask = cv2.dilate(red_mask, kernal)\n",
    "        res_red = cv2.bitwise_and(traffic_img, traffic_img, \n",
    "                                  mask = red_mask)\n",
    "\n",
    "        # For green color\n",
    "        green_mask = cv2.dilate(green_mask, kernal)\n",
    "        res_green = cv2.bitwise_and(traffic_img, traffic_img,\n",
    "                                    mask = green_mask)\n",
    "\n",
    "\n",
    "        # Creating contour to track red color\n",
    "        contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "        rg_eixit = False\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 190):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht), \n",
    "                                           (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "                cv2.putText(img, \"RED:\"+label+confidence, (x, y), font, 2, (0, 0, 255), 2) #put into text\n",
    "                rg_eixit = True\n",
    "                current_sig = \"RED\"\n",
    "\n",
    "        # Creating contour to track green color\n",
    "        contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 300):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht),\n",
    "                                           (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                cv2.putText(img, \"GREEN:\"+label + confidence, (x, y), font, 2, (0, 255, 0), 2) #put into text\n",
    "                rg_eixit = True\n",
    "                current_sig = \"GREEN\"\n",
    "\n",
    "        if not rg_eixit:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "\n",
    "    else:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "        cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "        \n",
    "    # #############################################################\n",
    "    if label in ['person', 'bicycle', 'car', 'motorbike', 'bus', 'train', 'truck']:\n",
    "#         print('car')\n",
    "        iou = intersection_over_union(box1, [x,y,w,h])\n",
    "#         iou = intersection_over_union([x,y,w,h],box1)\n",
    "        car_iou_max = max(iou, car_iou_max)\n",
    "        if iou != 0 and car_iou_max == iou:\n",
    "#         print(iou)\n",
    "#         print('car true')\n",
    "#         print([x,y,w,h])\n",
    "            if car_iou_max > 0.18:\n",
    "                car_speed = 'stop'\n",
    "            elif 0.18 >= car_iou_max >0.01:\n",
    "                car_speed = 'decrease'\n",
    "            else:\n",
    "                car_speed = 'increase'\n",
    "            condition = car_speed\n",
    "\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "            cv2.putText(img, 'Car status: '+condition,(x, y+50), font, 2, (100, 70, 200), 2) #put into text\n",
    "    \n",
    "    if label == 'stop sign':\n",
    "        stop_sign = 'stop sign'\n",
    "        \n",
    "print(current_sig)\n",
    "print(car_speed)\n",
    "print(stop_sign)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#save matrix/array as image file\n",
    "isWritten = cv2.imwrite('image-3.jpg', img)\n",
    "\n",
    "if isWritten:\n",
    "    print('Image is successfully saved as file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a576ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cacd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c87ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4112a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RED\n",
      "stop\n",
      "None\n",
      "Image is successfully saved as file.\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('image3.jpg')\n",
    "\n",
    "height, width, _ = img.shape\n",
    "center_y, center_x = height/2, width/2\n",
    "height_range, width_range = height/7, width/7\n",
    "box1 = [center_x-width_range, center_y-height_range, center_x+width_range, center_y+height_range]\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "output_laters_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_laters_names)\n",
    "\n",
    "boxes = [] \n",
    "confidences = [] \n",
    "class_ids = [] \n",
    "current_sig = None \n",
    "car_speed = \"increase\" \n",
    "car_iou_max = 0\n",
    "stop_sign = 'None'\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:] #used to store all the classes prediction\n",
    "        # we want to identify scores\n",
    "        class_id = np.argmax(scores) \n",
    "        confidence = scores[class_id] # assign into confidence variable. \n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width) #x *width\n",
    "            center_y = int(detection[1]*height) #y *height\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            # to get position of upper left corner\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "    \n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "traffic_light = []\n",
    "for i in indexes.flatten(): # loop to identify object detected\n",
    "    x, y, w, h = boxes[i] # extrac information back to boxes\n",
    "    label = str(classes[class_ids[i]]) # extrack back to 'str' cuz here only show number\n",
    "    confidence = str(round(confidences[i],2)) # extract confidences to str that show in pics\n",
    "    color = colors[i] # randomly pick colors to show each of object\n",
    "    condition = ''\n",
    "    \n",
    "    if label == 'traffic light':\n",
    "        traffic_img = img[y:y+h, x:x+w]\n",
    "        # Convert the image in BGR to HSV(hue-saturation-value) color space\n",
    "        hsvFrame = cv2.cvtColor(traffic_img, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "        # Set range for red color and \n",
    "        # define mask\n",
    "        red_lower = np.array([136, 87, 91], np.uint8)\n",
    "        red_upper = np.array([180, 255, 255], np.uint8)\n",
    "        red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "        # Set range for green color and \n",
    "        # define mask\n",
    "        green_lower = np.array([55, 102, 122], np.uint8)\n",
    "        green_upper = np.array([102, 255, 255], np.uint8)\n",
    "        green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "\n",
    "\n",
    "        # Morphological Transform, Dilation\n",
    "        # for each color and bitwise_and operator\n",
    "        # between imageFrame and mask determines\n",
    "        # to detect only that particular color\n",
    "        kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "        # For red color\n",
    "        red_mask = cv2.dilate(red_mask, kernal)\n",
    "        res_red = cv2.bitwise_and(traffic_img, traffic_img, \n",
    "                                  mask = red_mask)\n",
    "\n",
    "        # For green color\n",
    "        green_mask = cv2.dilate(green_mask, kernal)\n",
    "        res_green = cv2.bitwise_and(traffic_img, traffic_img,\n",
    "                                    mask = green_mask)\n",
    "\n",
    "\n",
    "        # Creating contour to track red color\n",
    "        contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "        rg_eixit = False\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 190):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht), \n",
    "                                           (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "                cv2.putText(img, \"RED:\"+label+confidence, (x, y), font, 2, (0, 0, 255), 2) #put into text\n",
    "                rg_eixit = True\n",
    "                current_sig = \"RED\"\n",
    "\n",
    "        # Creating contour to track green color\n",
    "        contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                               cv2.RETR_TREE,\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for pic, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 300):\n",
    "                xt, yt, wt, ht = cv2.boundingRect(contour)\n",
    "                traffic_img = cv2.rectangle(traffic_img, (xt, yt), \n",
    "                                           (xt + wt, yt + ht),\n",
    "                                           (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                cv2.putText(img, \"GREEN:\"+label + confidence, (x, y), font, 2, (0, 255, 0), 2) #put into text\n",
    "                rg_eixit = True\n",
    "                current_sig = \"GREEN\"\n",
    "\n",
    "        if not rg_eixit:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "\n",
    "    else:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "        cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255, 255, 255), 2) #put into text\n",
    "        \n",
    "    if label in ['person', 'bicycle', 'car', 'motorbike', 'bus', 'train', 'truck']:\n",
    "        iou = intersection_over_union(box1, [x,y,w,h])\n",
    "        car_iou_max = max(iou, car_iou_max)\n",
    "        if iou != 0 and car_iou_max == iou:\n",
    "\n",
    "            if car_iou_max > 0.18:\n",
    "                car_speed = 'stop'\n",
    "            elif 0.18 >= car_iou_max >0.01:\n",
    "                car_speed = 'decrease'\n",
    "            else:\n",
    "                car_speed = 'increase'\n",
    "            condition = car_speed\n",
    "\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # create rectangle\n",
    "            cv2.putText(img, 'Car status: '+condition,(x, y+50), font, 2, (100, 70, 200), 2) #put into text\n",
    "    \n",
    "    if label == 'stop sign':\n",
    "        stop_sign = 'stop sign'\n",
    "        \n",
    "print(current_sig)\n",
    "print(car_speed)\n",
    "print(stop_sign)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#save matrix/array as image file\n",
    "isWritten = cv2.imwrite('image-3.jpg', img)\n",
    "\n",
    "if isWritten:\n",
    "    print('Image is successfully saved as file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8942c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
